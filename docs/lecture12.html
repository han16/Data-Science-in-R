<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Shengtong" />

<meta name="date" content="2018-11-14" />

<title>lecture12</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Code</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://han16.github.io/Data-Science-in-R/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">lecture12</h1>
<h4 class="author"><em>Shengtong</em></h4>
<h4 class="date"><em>2018-11-14</em></h4>

</div>


<p><strong>Last updated:</strong> 2018-11-14</p>
<strong>workflowr checks:</strong> <small>(Click a bullet for more information)</small>
<ul>
<li>
<p><details> <summary> <strong style="color:red;">✖</strong> <strong>R Markdown file:</strong> uncommitted changes </summary> The R Markdown is untracked by Git. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Environment:</strong> empty </summary></p>
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Seed:</strong> <code>set.seed(20181026)</code> </summary></p>
<p>The command <code>set.seed(20181026)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Session information:</strong> recorded </summary></p>
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Repository version:</strong> <a href="https://github.com/han16/Data-Science-in-R/tree/fd915dffc686b5b8565657a9c2727b3b3bf6b16c" target="_blank">fd915df</a> </summary></p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .RData
    Ignored:    .Rhistory
    Ignored:    analysis/.DS_Store
    Ignored:    analysis/.Rapp.history
    Ignored:    analysis/.Rhistory
    Ignored:    analysis/figure/
    Ignored:    docs/.DS_Store

Untracked files:
    Untracked:  analysis/lecture12.Rmd
    Untracked:  docs/bcl-data.csv
    Untracked:  docs/shiny/
    Untracked:  docs/shiny_separate/

Unstaged changes:
    Modified:   analysis/index.Rmd

</code></pre>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes. </details>
</li>
</ul>
<hr />
<pre class="r"><code>########################################################
#### Go over HW 7 Shiny apps, check in on projects
####
#### Read https://juliasilge.com/blog/you-must-allow-me/ for next time
####
#### Today: Machine learning &amp; clustering
#### Projects due next week (in-class presentations)
######################################################


#=============================================================
## Principal components analysis
## Very awesome and intuitive description of PCA: 
##  https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579
#=============================================================

## Exploratory method for high-dimensional data (many similar methods exist,
## e.g. linear discriminant analysis)
##
## PCA = linear algebra technique to emphasize axes of variation in the data,
##   bring out strong patterns in a dataset, offers new coordinate system to 
##   emphasize variation in the data.
##
## Note 1: There are as many PCs as there are variables
## Note 2: Only works for numeric variables
## Note 3: Usually need to standardize the data (i.e., scale each column to have 
##   mean zero and unit sd) prior to PCA

library(tidyverse)
library(cowplot)
theme_set(theme_bw())
library(mvtnorm) ## Package to simulate multivariate normal data

#-------------------------------------------------------------
## First example : 2D example
#-------------------------------------------------------------

set.seed(12345)
cov &lt;- matrix(c(1,0.6,0.6,1), byrow=2, nrow=2)
sim &lt;- rmvnorm(100, mean=c(1,1), sigma = cov)
colnames(sim) &lt;- c(&quot;var1&quot;, &quot;var2&quot;)

## Let&#39;s fit a PCA
## Note: we used center = TRUE and scale = TRUE to standardize data!
sim_pca &lt;- prcomp(sim, center=TRUE, scale=TRUE)$x
colnames(sim_pca) &lt;- c(&quot;var1&quot;, &quot;var2&quot;)

sim_df &lt;- data.frame(rbind(data.frame(sim, type=&quot;Original variables&quot;),
                           data.frame(sim_pca, type=&quot;PC1 &amp; PC2&quot;)))
ggplot(sim_df, aes(var1, var2)) + geom_point() + facet_wrap(~type)

## Look at this nice visual example: http://setosa.io/ev/principal-component-analysis/

#-------------------------------------------------------------
## Next example : Iris data (4 dimensions)
#-------------------------------------------------------------

library(GGally)
data(iris)
## Note: how well we can distiguish between species depends on the plotting strategy/chosen variables
ggpairs(iris, columns = 1:4, ggplot2::aes(colour=Species), 
        upper=list(continuous=&quot;blank&quot;))

## Let&#39;s fit a PCA and look at the output
iris_pca &lt;- prcomp(select(iris, -Species), center=TRUE, scale=TRUE)
summary(iris_pca)
## Rotation matrix: loadings (sort of) represent the percent of variance 
## explained by the variable
iris_pca$rotation
## Actual principal components
head(iris_pca$x)
## Standard deviation of components represents the percent of variation each component explains
iris_pca$sdev
## Compute variance explained:
## Note: by definition, PC1 explains the most variation, PC2 the second most variation, ...
(iris_pca$sdev)^2 / (sum(iris_pca$sdev^2))
## Double check PCs
PC_check &lt;- as.matrix(scale(iris[,-5], center=TRUE, scale=TRUE)) %*% iris_pca$rotation
all.equal(PC_check, iris_pca$x)

## Now plot the PCs: PC1 vs PC2
iris_pca_dat &lt;- cbind(iris, iris_pca$x)
ggplot(iris_pca_dat, aes(x=PC1, y=PC2, color=Species)) + 
  geom_point() + 
  stat_ellipse()
## PC1 vs PC3
ggplot(iris_pca_dat, aes(x=PC1, y=PC3, color=Species)) + 
  geom_point() + 
  stat_ellipse()

## Visualizing PCA: Loadings
## =&gt; Petal.Length/Petal.Width load positively on PC1 but not PC2
## =&gt; Sepal.Width is orthogonal to petals (i.e., it captures uncorrelated information)
loadings &lt;- as.data.frame(iris_pca$rotation)
loadings$variable &lt;- rownames(loadings)
arrow_style &lt;- arrow(length = unit(0.05, &quot;inches&quot;), type = &quot;closed&quot;)
ggplot(loadings) +
  geom_segment(x=0, y=0, aes(xend=PC1, yend=PC2), arrow=arrow_style) +
  geom_text(aes(x=PC1, y=PC2, label=variable), size=3, color=&#39;red&#39;) +
  xlim(-1.,1) +
  ylim(-1.,1.) +
  coord_fixed()

#-------------------------------------------------------------
## How many principal components to choose in practice?
#-------------------------------------------------------------

## Recall: as many principal components as variables
## However, goal here is to reduce complexity of the data and summarize with
##   fewer dimensions

## Visualizing PCA: Variance explained
var_explained &lt;- data.frame(value=(iris_pca$sdev)^2 / (sum(iris_pca$sdev^2)),
                            PC = colnames(iris_pca$x))
ggplot(var_explained, aes(x = PC, y = value)) +
  geom_bar(stat = &quot;identity&quot;)

cumsum(var_explained$value)

## Base R graphics
plot(iris_pca)
biplot(iris_pca) ## Biplot represents both observations and variables on the same plot
screeplot(iris_pca)
pairs(iris_pca$x, col=iris$Species, pch=20, cex=2)

### Chalkboard: So what does PCA actually do? Link with singular value decomposition 

scale_iris &lt;- scale(select(iris, -Species), center=TRUE, scale=TRUE)
SVD &lt;- svd(scale_iris)
pairs(t(t(SVD$u) * SVD$d), col=iris$Species, pch=20, cex=2)
SVD.2 &lt;- svd(t(scale_iris))
pairs(SVD.2$v, col=iris$Species, pch=20, cex=2)

#-------------------------------------------------------------
## In class exercise:
## Read in wine.csv dataset. Note that the Cultivar variable is
##  categorical and should be removed prior to the PCA analysis.
## (1) Create scatterplots between all pairs of variables. Are Cultivar groupings obvious?
## (2) We will use PCA analysis to identify the variables contributing 
##  the most to variation in the data, and try to recover the Cultivar clusters.
## (3) How many PC&#39;s seem appropriate here? Which variables contribute
##  the most to the first principal component?
## (4) Create plots of loading lines (the rotation matrix) for PC1 and PC3. 
## (5) Create scatterplots of PC1 vs PC2 and PC1 vs PC3. Which PCs, if any, discriminate
##   among Cultivars. Is the PCA better at discriminating cultivars than the 
##   original scatterplots?
#-------------------------------------------------------------

wine &lt;- read_csv(&quot;wine.csv&quot;)
## Note: how well we can distiguish between species depends on the plotting strategy/chosen variables
ggpairs(wine, columns = 2:9, ggplot2::aes(colour=Cultivar), 
        upper=list(continuous=&quot;blank&quot;))
wine_pca &lt;- prcomp(select(wine, -Cultivar), center=TRUE, scale=TRUE)
plot(wine_pca)
summary(wine_pca)
wine_pca$rotation
loadings &lt;- as.data.frame(wine_pca$rotation)
loadings$variable &lt;- rownames(loadings)
arrow_style &lt;- arrow(length = unit(0.05, &quot;inches&quot;), type = &quot;closed&quot;)
ggplot(loadings) +
  geom_segment(x=0, y=0, aes(xend=PC1, yend=PC2), arrow=arrow_style) +
  geom_text(aes(x=PC1, y=PC2, label=variable), size=3, color=&#39;red&#39;) +
  xlim(-1.,1) +
  ylim(-1.,1.) +
  coord_fixed()
wine_pca_labels &lt;- data.frame(wine_pca$x, Cultivar=factor(wine$Cultivar))
ggplot(wine_pca_labels) +
  geom_point(aes(x=PC1, y=PC2, color=Cultivar))
ggplot(wine_pca_labels) +
  geom_point(aes(x=PC1, y=PC2))

## Going a little bit further, PCA in real analyses:
## (1) Genes Mirror Geography in Europe, Novembre et al (2008)
## (2) Genomic Insights into the Peopling of the Southwest Pacific, Skoglund et al (2016)

#=============================================================
## Clustering analysis: K-means, hierarchical clustering, mixture models, ....
#=============================================================

## Clustering = family of approaches to identify previously unknown or
##   undetected groupings in data
## We need:
## (1) Measure of distance and/or similarity among data points
## (2) Clustering algorithm to create the groupings

## We will make use of the Ruspini data set for this part
library(cluster)
data(ruspini)
plot(ruspini)

## Clustering methods are based on &quot;distance&quot; between points.
## As with PCA, in order to standardize these &quot;distances&quot; we need to standardize the data,
##   i.e., we should scale each column of data to have mean zero and unit sd

rus_scaled &lt;- scale(ruspini)
plot(rus_scaled, pch=20, cex=2)

#=============================================================
## K-means algorithm
## Cluster data into k groups of equal variance by minimizing 
##   the within-cluster sum of squares
#=============================================================

km &lt;- kmeans(rus_scaled, centers=2)

plot(rus_scaled, col=km$cluster, pch=20, cex=2)
points(km$centers, pch=3, cex=2)           ## this adds the centroids
#text(km$centers, labels=1:4, pos=2, cex=2) ## this adds the cluster ID

## What did this algorithm just do?
## Chalkboard Discussion of K-means clustering 
##
## 1. Place k &quot;centroids&quot; in the data
## 2. Assign point to cluster k based on Euclidean distance
## 3. Re-compute each of the k centroids based on means of associated points
## 4. Re-assign centroids
## 5. Repeat until convergence
## =&gt; Look at this: https://www.naftaliharris.com/blog/visualizing-k-means-clustering/

## How to choose number of clusters k?
## Simplest method: run with several different values for k.
##   For each k, calculate the within cluster sum of squares (WSS)
##   Plot k versus WSS, look for the &quot;elbow&quot; (very subjective!)

wss &lt;- rep(NA, 10)
for(k in 1:10){
  wss[k] &lt;- kmeans(rus_scaled, centers=k)$tot.withinss
}
plot(1:10, wss, type=&#39;l&#39;, xlab=&#39;k&#39;, ylab=&#39;WSS&#39;)

## Let&#39;s compare the results for K=4 and K=5 clusters: Which looks better to you?
km_4 &lt;- kmeans(rus_scaled, centers=4, nstart=10)
km_5 &lt;- kmeans(rus_scaled, centers=5, nstart=10)
rus_df &lt;- data.frame(rbind(cbind(rus_scaled, Clusters=km_4$cluster, K=&quot;K=4&quot;),
                           cbind(rus_scaled, Clusters=km_5$cluster, K=&quot;K=5&quot;)))
rus_df$Clusters &lt;- factor(rus_df$Clusters)
rus_df &lt;- rus_df %&gt;% mutate(x=as.numeric(as.character(x)), 
                            y=as.numeric(as.character(y)))
ggplot(rus_df, aes(x,y, color=Clusters)) + 
  geom_point() + 
  facet_wrap(~K)

## Note: broom package also works here!
library(broom)
rus_scaled %&gt;%
  kmeans(5) %&gt;%
  augment(rus_scaled) %&gt;%
  head()
rus_scaled %&gt;%
  kmeans(5) %&gt;%
  tidy()

## Some caveats:
## (1) Clustering depends on initial conditions
## (2) Algorithm guaranteed to converge, but maybe on local optima
## (3) No way to know if clusters have meaning beyond the math (but this is true for
##   all clustering methods!)

#-------------------------------------------------------------
## In class exercise:
## Perform K-means on the wine data, using the elbow method to 
##   identify the number of clusters k.
## Repeat for 3 different initializations (set seed each time),
##   and compare your results. Are the results consistent? Do
##   cultivars seem to belong to, or not, a specific cluster?
#-------------------------------------------------------------

wine_scaled &lt;- scale(wine[,-1])
wss &lt;- rep(NA, 20)
for(k in 1:20) {
  wss[k] &lt;- kmeans(wine_scaled, centers = k)$tot.withinss
}
plot(1:20, wss, type = &quot;l&quot;)
abline(v=3, lty=2)

km_run &lt;- matrix(NA, nrow=nrow(wine_scaled), ncol=3)
for(i in 1:3) {
  set.seed(i+1)
  km_run[,i] &lt;- kmeans(wine_scaled, centers = 3)$cluster
}

#=============================================================
## Hierarchical clustering and dendrograms
## Difference between different linkage types (advantages, disadvantages)
## Difference between agglomerative (bottom up) and divisive (top down)
#=============================================================

## Useful when data have a hierarchical structure
## Very commonly used in genomics applications!
## Stable since no initialization step
##  
## At each step, &quot;closest&quot; genes are clustered, then calculate the distance 
##   between this new group and remaining ones
## Linkage: simple, complete, average, ...
##
## K chosen according to the tree

d &lt;- dist(rus_scaled)
hc &lt;- hclust(d, method=&quot;complete&quot;)
## Look at the result
plot(hc)
rect.hclust(hc, k=4)

## Without the leaf labels
plot(as.dendrogram(hc), leaflab=&quot;none&quot;)
rect.hclust(hc, k=4)

## Look at how the data are clustered with 4 clusters
cluster.complete &lt;- cutree(hc, k=4)
plot(rus_scaled, col=cluster.complete, cex=2, pch=20)

## Chalk-board Discussion of Hierarchical Clustering 

### With 5 clusters
cluster.complete &lt;- cutree(hc, k=5)
plot(rus_scaled, col=cluster.complete, cex=2, pch=20)

### Cluster with single linkage rather than complete linkage
hc.single &lt;- hclust(d, method=&quot;single&quot;)
plot(as.dendrogram(hc.single), leaflab=&quot;none&quot;)
rect.hclust(hc.single, k=4)

par(mfrow=c(1,2))
cluster.single &lt;- cutree(hc.single, k=4)
plot(rus_scaled, col=cluster.single, pch=20, cex=2, main=&quot;Single Linkage&quot;)
clust &lt;- cutree(hc, k=4)
plot(rus_scaled, col=clust, pch=20, cex=2, main=&quot;Complete Linkage&quot;)


#-------------------------------------------------------------
## In class exercise:
## Perform hierarchical clustering on the wine data, using
##   complete, single, and average linkage. How stable are results
##   for different types of linkage?
#-------------------------------------------------------------



#=============================================================
## Comparing data clusterings : the (adjusted) Rand index
#=============================================================

## Related to accuracy:
## a = # of pairs of observations that are in the same cluster in X and same cluster in Y
## b = # of pairs of observations that are in different clusters in X and different clusters in Y
## c = # of pairs of observations that are in the same cluster in X and different clusters in Y
## d = # of pairs of observations that are in differenet clusters in X and the same cluster in Y
## Rand index = (a+b) / (a+b+c+d)

## Rand index is a measure of similarity between two data clusterings (between 0 and 1)
library(clusteval)
cluster_similarity(km_4$cluster, km_5$cluster, similarity = &quot;rand&quot;)

## The adjusted Rand index is adjusted for the chance grouping of elements:
library(mclust)
adjustedRandIndex(km_4$cluster, km_5$cluster)

## 1 = perfect greement, 0 = clusterings do not agree on any pair of points



#=============================================================
## Next time: 
## Regular expressions, Sentiment analysis, quick review for final take-home exam!
#=============================================================</code></pre>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] workflowr_1.1.1   Rcpp_0.12.19      digest_0.6.18    
 [4] rprojroot_1.3-2   R.methodsS3_1.7.1 backports_1.1.2  
 [7] git2r_0.23.0      magrittr_1.5      evaluate_0.12    
[10] stringi_1.2.4     whisker_0.3-2     R.oo_1.22.0      
[13] R.utils_2.7.0     rmarkdown_1.10    tools_3.5.1      
[16] stringr_1.3.1     yaml_2.2.0        compiler_3.5.1   
[19] htmltools_0.3.6   knitr_1.20       </code></pre>
</div>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<hr>
<p>
  This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a>
  analysis was created with
  <a href="https://github.com/jdblischak/workflowr">workflowr</a> 1.1.1
</p>
<hr>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
