<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Shengtong" />

<meta name="date" content="2018-11-14" />

<title>lecture12</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Code</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://han16.github.io/Data-Science-in-R/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">lecture12</h1>
<h4 class="author"><em>Shengtong</em></h4>
<h4 class="date"><em>2018-11-14</em></h4>

</div>


<p><strong>Last updated:</strong> 2018-11-15</p>
<strong>workflowr checks:</strong> <small>(Click a bullet for more information)</small>
<ul>
<li>
<p><details> <summary> <strong style="color:red;">✖</strong> <strong>R Markdown file:</strong> uncommitted changes </summary> The R Markdown file has unstaged changes. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Environment:</strong> empty </summary></p>
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Seed:</strong> <code>set.seed(20181026)</code> </summary></p>
<p>The command <code>set.seed(20181026)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Session information:</strong> recorded </summary></p>
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Repository version:</strong> <a href="https://github.com/han16/Data-Science-in-R/tree/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd" target="_blank">2b7ee1b</a> </summary></p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
<pre><code>
Ignored files:
    Ignored:    analysis/.Rhistory
    Ignored:    analysis/figure/
    Ignored:    analysis/shiny/.Rhistory
    Ignored:    docs/shiny/.Rhistory

Untracked files:
    Untracked:  analysis/wine.csv

Unstaged changes:
    Modified:   analysis/lecture12.Rmd

</code></pre>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes. </details>
</li>
</ul>
<details> <summary> <small><strong>Expand here to see past versions:</strong></small> </summary>
<ul>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
File
</th>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
<th style="text-align:left;">
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/analysis/lecture12.Rmd" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
<td style="text-align:left;">
Nov142018
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/han16/Data-Science-in-R/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/lecture12.html" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
<td style="text-align:left;">
Nov142018
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/c828177875bf8c7bd13995d12c96fbd8a33ce8cd/analysis/lecture12.Rmd" target="_blank">c828177</a>
</td>
<td style="text-align:left;">
han16
</td>
<td style="text-align:left;">
2018-11-14
</td>
<td style="text-align:left;">
Nov142018
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/han16/Data-Science-in-R/c828177875bf8c7bd13995d12c96fbd8a33ce8cd/docs/lecture12.html" target="_blank">c828177</a>
</td>
<td style="text-align:left;">
han16
</td>
<td style="text-align:left;">
2018-11-14
</td>
<td style="text-align:left;">
Nov142018
</td>
</tr>
</tbody>
</table>
</ul>
<p></details></p>
<hr />
<pre class="r"><code>########################################################
#### Go over HW 7 Shiny apps, check in on projects
####
#### Read https://juliasilge.com/blog/you-must-allow-me/ for next time
####
#### Today: Machine learning &amp; clustering
#### Projects due next week (in-class presentations)
######################################################


#=============================================================
## Principal components analysis
## Very awesome and intuitive description of PCA: 
##  https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579
#=============================================================

## Exploratory method for high-dimensional data (many similar methods exist,
## e.g. linear discriminant analysis)
##
## PCA = linear algebra technique to emphasize axes of variation in the data,
##   bring out strong patterns in a dataset, offers new coordinate system to 
##   emphasize variation in the data.
##
## Note 1: There are as many PCs as there are variables
## Note 2: Only works for numeric variables
## Note 3: Usually need to standardize the data (i.e., scale each column to have 
##   mean zero and unit sd) prior to PCA

library(tidyverse)</code></pre>
<pre><code>-- Attaching packages ------------------------------------------------------------------------------- tidyverse 1.2.1 --</code></pre>
<pre><code>v ggplot2 3.1.0     v purrr   0.2.5
v tibble  1.4.2     v dplyr   0.7.7
v tidyr   0.8.2     v stringr 1.3.1
v readr   1.1.1     v forcats 0.3.0</code></pre>
<pre><code>-- Conflicts ---------------------------------------------------------------------------------- tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(cowplot)</code></pre>
<pre><code>
Attaching package: &#39;cowplot&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:ggplot2&#39;:

    ggsave</code></pre>
<pre class="r"><code>theme_set(theme_bw())
library(mvtnorm) ## Package to simulate multivariate normal data</code></pre>
<div id="first-example-2d-example" class="section level2">
<h2>First example : 2D example</h2>
<pre class="r"><code>set.seed(12345)
cov &lt;- matrix(c(1,0.6,0.6,1), byrow=2, nrow=2)
sim &lt;- rmvnorm(100, mean=c(1,1), sigma = cov)
colnames(sim) &lt;- c(&quot;var1&quot;, &quot;var2&quot;)

## Let&#39;s fit a PCA
## Note: we used center = TRUE and scale = TRUE to standardize data!
sim_pca &lt;- prcomp(sim, center=TRUE, scale=TRUE)$x
colnames(sim_pca) &lt;- c(&quot;var1&quot;, &quot;var2&quot;)

sim_df &lt;- data.frame(rbind(data.frame(sim, type=&quot;Original variables&quot;),
                           data.frame(sim_pca, type=&quot;PC1 &amp; PC2&quot;)))
ggplot(sim_df, aes(var1, var2)) + geom_point() + facet_wrap(~type)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-2-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-2-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>## Look at this nice visual example: http://setosa.io/ev/principal-component-analysis/</code></pre>
</div>
<div id="next-example-iris-data-4-dimensions" class="section level2">
<h2>Next example : Iris data (4 dimensions)</h2>
<pre class="r"><code>library(GGally)</code></pre>
<pre><code>
Attaching package: &#39;GGally&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:dplyr&#39;:

    nasa</code></pre>
<pre class="r"><code>data(iris)
## Note: how well we can distiguish between species depends on the plotting strategy/chosen variables
ggpairs(iris, columns = 1:4, ggplot2::aes(colour=Species), 
        upper=list(continuous=&quot;blank&quot;))</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-3-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-3-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>## Let&#39;s fit a PCA and look at the output
iris_pca &lt;- prcomp(select(iris, -Species), center=TRUE, scale=TRUE)
summary(iris_pca)</code></pre>
<pre><code>Importance of components:
                          PC1    PC2     PC3     PC4
Standard deviation     1.7084 0.9560 0.38309 0.14393
Proportion of Variance 0.7296 0.2285 0.03669 0.00518
Cumulative Proportion  0.7296 0.9581 0.99482 1.00000</code></pre>
<pre class="r"><code>## Rotation matrix: loadings (sort of) represent the percent of variance 
## explained by the variable
iris_pca$rotation</code></pre>
<pre><code>                    PC1         PC2        PC3        PC4
Sepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863
Sepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096
Petal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492
Petal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971</code></pre>
<pre class="r"><code>## Actual principal components
head(iris_pca$x)</code></pre>
<pre><code>           PC1        PC2         PC3          PC4
[1,] -2.257141 -0.4784238  0.12727962  0.024087508
[2,] -2.074013  0.6718827  0.23382552  0.102662845
[3,] -2.356335  0.3407664 -0.04405390  0.028282305
[4,] -2.291707  0.5953999 -0.09098530 -0.065735340
[5,] -2.381863 -0.6446757 -0.01568565 -0.035802870
[6,] -2.068701 -1.4842053 -0.02687825  0.006586116</code></pre>
<pre class="r"><code>## Standard deviation of components represents the percent of variation each component explains
iris_pca$sdev</code></pre>
<pre><code>[1] 1.7083611 0.9560494 0.3830886 0.1439265</code></pre>
<pre class="r"><code>## Compute variance explained:
## Note: by definition, PC1 explains the most variation, PC2 the second most variation, ...
(iris_pca$sdev)^2 / (sum(iris_pca$sdev^2))</code></pre>
<pre><code>[1] 0.729624454 0.228507618 0.036689219 0.005178709</code></pre>
<pre class="r"><code>## Double check PCs
PC_check &lt;- as.matrix(scale(iris[,-5], center=TRUE, scale=TRUE)) %*% iris_pca$rotation
all.equal(PC_check, iris_pca$x)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>## Now plot the PCs: PC1 vs PC2
iris_pca_dat &lt;- cbind(iris, iris_pca$x)
ggplot(iris_pca_dat, aes(x=PC1, y=PC2, color=Species)) + 
  geom_point() + 
  stat_ellipse()</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-3-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-3-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-3-2.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>## PC1 vs PC3
ggplot(iris_pca_dat, aes(x=PC1, y=PC3, color=Species)) + 
  geom_point() + 
  stat_ellipse()</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-3-3.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-3-3.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-3-3.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>## Visualizing PCA: Loadings
## =&gt; Petal.Length/Petal.Width load positively on PC1 but not PC2
## =&gt; Sepal.Width is orthogonal to petals (i.e., it captures uncorrelated information)
loadings &lt;- as.data.frame(iris_pca$rotation)
loadings$variable &lt;- rownames(loadings)
arrow_style &lt;- arrow(length = unit(0.05, &quot;inches&quot;), type = &quot;closed&quot;)
ggplot(loadings) +
  geom_segment(x=0, y=0, aes(xend=PC1, yend=PC2), arrow=arrow_style) +
  geom_text(aes(x=PC1, y=PC2, label=variable), size=3, color=&#39;red&#39;) +
  xlim(-1.,1) +
  ylim(-1.,1.) +
  coord_fixed()</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-4-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-4-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>#-------------------------------------------------------------
## How many principal components to choose in practice?
#-------------------------------------------------------------

## Recall: as many principal components as variables
## However, goal here is to reduce complexity of the data and summarize with
##   fewer dimensions

## Visualizing PCA: Variance explained
var_explained &lt;- data.frame(value=(iris_pca$sdev)^2 / (sum(iris_pca$sdev^2)),
                            PC = colnames(iris_pca$x))
ggplot(var_explained, aes(x = PC, y = value)) +
  geom_bar(stat = &quot;identity&quot;)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-5-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-5-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>cumsum(var_explained$value)</code></pre>
<pre><code>[1] 0.7296245 0.9581321 0.9948213 1.0000000</code></pre>
<pre class="r"><code>## Base R graphics
plot(iris_pca)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-6-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-6-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>biplot(iris_pca) ## Biplot represents both observations and variables on the same plot</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-6-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-6-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-6-2.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>screeplot(iris_pca)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-6-3.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-6-3.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-6-3.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>pairs(iris_pca$x, col=iris$Species, pch=20, cex=2)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-6-4.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-6-4.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-6-4.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>### Chalkboard: So what does PCA actually do? Link with singular value decomposition 

scale_iris &lt;- scale(select(iris, -Species), center=TRUE, scale=TRUE)
SVD &lt;- svd(scale_iris)
pairs(t(t(SVD$u) * SVD$d), col=iris$Species, pch=20, cex=2)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-7-1.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-7-1.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>SVD.2 &lt;- svd(t(scale_iris))
pairs(SVD.2$v, col=iris$Species, pch=20, cex=2)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-7-2.png" width="672" style="display: block; margin: auto;" /></p>
<details> <summary><em>Expand here to see past versions of unnamed-chunk-7-2.png:</em></summary>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<a href="https://github.com/han16/Data-Science-in-R/blob/2b7ee1bf42ee48a2126ef53d29a9a48d0fd0d3bd/docs/figure/lecture12.Rmd/unnamed-chunk-7-2.png" target="_blank">2b7ee1b</a>
</td>
<td style="text-align:left;">
Shengtong
</td>
<td style="text-align:left;">
2018-11-14
</td>
</tr>
</tbody>
</table>
<p></details></p>
<pre class="r"><code>#-------------------------------------------------------------
## In class exercise:
## Read in wine.csv dataset. Note that the Cultivar variable is
##  categorical and should be removed prior to the PCA analysis.
## (1) Create scatterplots between all pairs of variables. Are Cultivar groupings obvious?
## (2) We will use PCA analysis to identify the variables contributing 
##  the most to variation in the data, and try to recover the Cultivar clusters.
## (3) How many PC&#39;s seem appropriate here? Which variables contribute
##  the most to the first principal component?
## (4) Create plots of loading lines (the rotation matrix) for PC1 and PC3. 
## (5) Create scatterplots of PC1 vs PC2 and PC1 vs PC3. Which PCs, if any, discriminate
##   among Cultivars. Is the PCA better at discriminating cultivars than the 
##   original scatterplots?
#-------------------------------------------------------------

wine &lt;- read.csv(&quot;C:\\Shengtong\\Teaching\\PH718\\Code\\Data-Science-in-R\\analysis\\wine.csv&quot;)
## Note: how well we can distiguish between species depends on the plotting strategy/chosen variables
ggpairs(wine, columns = 2:9, ggplot2::aes(colour=Cultivar), 
        upper=list(continuous=&quot;blank&quot;))</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>wine_pca &lt;- prcomp(select(wine, -Cultivar), center=TRUE, scale=TRUE)
plot(wine_pca)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(wine_pca)</code></pre>
<pre><code>Importance of components:
                          PC1    PC2    PC3    PC4     PC5     PC6     PC7
Standard deviation     1.6403 1.4036 0.9758 0.9118 0.82748 0.63651 0.59091
Proportion of Variance 0.3363 0.2462 0.1190 0.1039 0.08559 0.05064 0.04365
Cumulative Proportion  0.3363 0.5826 0.7016 0.8055 0.89111 0.94175 0.98540
                          PC8
Standard deviation     0.3418
Proportion of Variance 0.0146
Cumulative Proportion  1.0000</code></pre>
<pre class="r"><code>wine_pca$rotation</code></pre>
<pre><code>                       PC1          PC2         PC3         PC4
Alcohol        -0.22654303  0.501465867 -0.40546435  0.21466476
MalicAcid       0.31157625  0.322362963 -0.02402787  0.07622524
Ash            -0.06559042  0.430407129  0.73311784  0.09876505
Magnesium      -0.25009429  0.318535452  0.16787273 -0.80749990
TotalPhenol    -0.53747068  0.004786501  0.10823030  0.32034021
Flavanoids     -0.55663487 -0.072794005  0.13105601  0.25795708
NonflavPhenols  0.42920190  0.136227208  0.35263552  0.32878655
Color           0.04263628  0.577943979 -0.34078880  0.09506746
                        PC5        PC6          PC7         PC8
Alcohol        -0.061544336 -0.1282794 -0.681546057  0.04449257
MalicAcid       0.865553459 -0.1591111  0.119692299 -0.06155780
Ash            -0.009604591  0.4838802 -0.151710216  0.07735021
Magnesium      -0.032273948 -0.3897976  0.037144643 -0.03724463
TotalPhenol     0.111965977 -0.3082298  0.307596024  0.62818264
Flavanoids      0.121640862 -0.1094416  0.095275330 -0.75185755
NonflavPhenols -0.352644293 -0.6528980 -0.001695339 -0.11890648
Color          -0.306927958  0.1971978  0.626958878 -0.11322052</code></pre>
<pre class="r"><code>loadings &lt;- as.data.frame(wine_pca$rotation)
loadings$variable &lt;- rownames(loadings)
arrow_style &lt;- arrow(length = unit(0.05, &quot;inches&quot;), type = &quot;closed&quot;)
ggplot(loadings) +
  geom_segment(x=0, y=0, aes(xend=PC1, yend=PC2), arrow=arrow_style) +
  geom_text(aes(x=PC1, y=PC2, label=variable), size=3, color=&#39;red&#39;) +
  xlim(-1.,1) +
  ylim(-1.,1.) +
  coord_fixed()</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-8-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>wine_pca_labels &lt;- data.frame(wine_pca$x, Cultivar=factor(wine$Cultivar))
ggplot(wine_pca_labels) +
  geom_point(aes(x=PC1, y=PC2, color=Cultivar))</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-8-4.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(wine_pca_labels) +
  geom_point(aes(x=PC1, y=PC2))</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-8-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Going a little bit further, PCA in real analyses:
## (1) Genes Mirror Geography in Europe, Novembre et al (2008)
## (2) Genomic Insights into the Peopling of the Southwest Pacific, Skoglund et al (2016)</code></pre>
<pre class="r"><code>#=============================================================
## Clustering analysis: K-means, hierarchical clustering, mixture models, ....
#=============================================================

## Clustering = family of approaches to identify previously unknown or
##   undetected groupings in data
## We need:
## (1) Measure of distance and/or similarity among data points
## (2) Clustering algorithm to create the groupings

## We will make use of the Ruspini data set for this part
library(cluster)
data(ruspini)
plot(ruspini)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Clustering methods are based on &quot;distance&quot; between points.
## As with PCA, in order to standardize these &quot;distances&quot; we need to standardize the data,
##   i.e., we should scale each column of data to have mean zero and unit sd

rus_scaled &lt;- scale(ruspini)
plot(rus_scaled, pch=20, cex=2)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-9-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="k-means-algorithm" class="section level2">
<h2>K-means algorithm</h2>
<pre class="r"><code>## Cluster data into k groups of equal variance by minimizing 
##   the within-cluster sum of squares
#=============================================================

km &lt;- kmeans(rus_scaled, centers=2)

plot(rus_scaled, col=km$cluster, pch=20, cex=2)
points(km$centers, pch=3, cex=2)           ## this adds the centroids</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#text(km$centers, labels=1:4, pos=2, cex=2) ## this adds the cluster ID</code></pre>
<pre class="r"><code>## What did this algorithm just do?
## Chalkboard Discussion of K-means clustering 
##
## 1. Place k &quot;centroids&quot; in the data
## 2. Assign point to cluster k based on Euclidean distance
## 3. Re-compute each of the k centroids based on means of associated points
## 4. Re-assign centroids
## 5. Repeat until convergence
## =&gt; Look at this: https://www.naftaliharris.com/blog/visualizing-k-means-clustering/

## How to choose number of clusters k?
## Simplest method: run with several different values for k.
##   For each k, calculate the within cluster sum of squares (WSS)
##   Plot k versus WSS, look for the &quot;elbow&quot; (very subjective!)

wss &lt;- rep(NA, 10)
for(k in 1:10){
  wss[k] &lt;- kmeans(rus_scaled, centers=k)$tot.withinss
}
plot(1:10, wss, type=&#39;l&#39;, xlab=&#39;k&#39;, ylab=&#39;WSS&#39;)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Let&#39;s compare the results for K=4 and K=5 clusters: Which looks better to you?
km_4 &lt;- kmeans(rus_scaled, centers=4, nstart=10)
km_5 &lt;- kmeans(rus_scaled, centers=5, nstart=10)
rus_df &lt;- data.frame(rbind(cbind(rus_scaled, Clusters=km_4$cluster, K=&quot;K=4&quot;),
                           cbind(rus_scaled, Clusters=km_5$cluster, K=&quot;K=5&quot;)))
rus_df$Clusters &lt;- factor(rus_df$Clusters)
rus_df &lt;- rus_df %&gt;% mutate(x=as.numeric(as.character(x)), 
                            y=as.numeric(as.character(y)))
ggplot(rus_df, aes(x,y, color=Clusters)) + 
  geom_point() + 
  facet_wrap(~K)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Note: broom package also works here!
library(broom)
rus_scaled %&gt;%
  kmeans(5) %&gt;%
  augment(rus_scaled) %&gt;%
  head()
rus_scaled %&gt;%
  kmeans(5) %&gt;%
  tidy()</code></pre>
<pre class="r"><code>## Some caveats:
## (1) Clustering depends on initial conditions
## (2) Algorithm guaranteed to converge, but maybe on local optima
## (3) No way to know if clusters have meaning beyond the math (but this is true for
##   all clustering methods!)

#-------------------------------------------------------------
## In class exercise:
## Perform K-means on the wine data, using the elbow method to 
##   identify the number of clusters k.
## Repeat for 3 different initializations (set seed each time),
##   and compare your results. Are the results consistent? Do
##   cultivars seem to belong to, or not, a specific cluster?
#-------------------------------------------------------------

wine_scaled &lt;- scale(wine[,-1])
wss &lt;- rep(NA, 20)
for(k in 1:20) {
  wss[k] &lt;- kmeans(wine_scaled, centers = k)$tot.withinss
}
plot(1:20, wss, type = &quot;l&quot;)
abline(v=3, lty=2)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>km_run &lt;- matrix(NA, nrow=nrow(wine_scaled), ncol=3)
for(i in 1:3) {
  set.seed(i+1)
  km_run[,i] &lt;- kmeans(wine_scaled, centers = 3)$cluster
}</code></pre>
</div>
<div id="hierarchical-clustering-and-dendrograms" class="section level2">
<h2>Hierarchical clustering and dendrograms</h2>
<pre class="r"><code>## Difference between different linkage types (advantages, disadvantages)
## Difference between agglomerative (bottom up) and divisive (top down)
#=============================================================

## Useful when data have a hierarchical structure
## Very commonly used in genomics applications!
## Stable since no initialization step
##  
## At each step, &quot;closest&quot; genes are clustered, then calculate the distance 
##   between this new group and remaining ones
## Linkage: simple, complete, average, ...
##
## K chosen according to the tree

d &lt;- dist(rus_scaled)
hc &lt;- hclust(d, method=&quot;complete&quot;)
## Look at the result
plot(hc)
rect.hclust(hc, k=4)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Without the leaf labels
plot(as.dendrogram(hc), leaflab=&quot;none&quot;)
rect.hclust(hc, k=4)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Look at how the data are clustered with 4 clusters
cluster.complete &lt;- cutree(hc, k=4)
plot(rus_scaled, col=cluster.complete, cex=2, pch=20)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Chalk-board Discussion of Hierarchical Clustering 

### With 5 clusters
cluster.complete &lt;- cutree(hc, k=5)
plot(rus_scaled, col=cluster.complete, cex=2, pch=20)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>### Cluster with single linkage rather than complete linkage
hc.single &lt;- hclust(d, method=&quot;single&quot;)
plot(as.dendrogram(hc.single), leaflab=&quot;none&quot;)
rect.hclust(hc.single, k=4)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-18-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow=c(1,2))
cluster.single &lt;- cutree(hc.single, k=4)
plot(rus_scaled, col=cluster.single, pch=20, cex=2, main=&quot;Single Linkage&quot;)
clust &lt;- cutree(hc, k=4)
plot(rus_scaled, col=clust, pch=20, cex=2, main=&quot;Complete Linkage&quot;)</code></pre>
<p><img src="figure/lecture12.Rmd/unnamed-chunk-18-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#-------------------------------------------------------------
## In class exercise:
## Perform hierarchical clustering on the wine data, using
##   complete, single, and average linkage. How stable are results
##   for different types of linkage?
#-------------------------------------------------------------



#=============================================================
## Comparing data clusterings : the (adjusted) Rand index
#=============================================================

## Related to accuracy:
## a = # of pairs of observations that are in the same cluster in X and same cluster in Y
## b = # of pairs of observations that are in different clusters in X and different clusters in Y
## c = # of pairs of observations that are in the same cluster in X and different clusters in Y
## d = # of pairs of observations that are in differenet clusters in X and the same cluster in Y
## Rand index = (a+b) / (a+b+c+d)

## Rand index is a measure of similarity between two data clusterings (between 0 and 1)
library(clusteval)
cluster_similarity(km_4$cluster, km_5$cluster, similarity = &quot;rand&quot;)</code></pre>
<pre><code>[1] 0.9783784</code></pre>
<pre class="r"><code>## The adjusted Rand index is adjusted for the chance grouping of elements:
library(mclust)</code></pre>
<pre><code>Package &#39;mclust&#39; version 5.4.1
Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<pre><code>
Attaching package: &#39;mclust&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:purrr&#39;:

    map</code></pre>
<pre class="r"><code>adjustedRandIndex(km_4$cluster, km_5$cluster)</code></pre>
<pre><code>[1] 0.9400231</code></pre>
<pre class="r"><code>## 1 = perfect greement, 0 = clusterings do not agree on any pair of points



#=============================================================
## Next time: 
## Regular expressions, Sentiment analysis, quick review for final take-home exam!
#=============================================================</code></pre>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] mclust_5.4.1    clusteval_0.1   bindrcpp_0.2.2  cluster_2.0.7-1
 [5] GGally_1.4.0    mvtnorm_1.0-8   cowplot_0.9.3   forcats_0.3.0  
 [9] stringr_1.3.1   dplyr_0.7.7     purrr_0.2.5     readr_1.1.1    
[13] tidyr_0.8.2     tibble_1.4.2    ggplot2_3.1.0   tidyverse_1.2.1

loaded via a namespace (and not attached):
 [1] tidyselect_0.2.5   reshape2_1.4.3     haven_1.1.2       
 [4] lattice_0.20-35    colorspace_1.3-2   htmltools_0.3.6   
 [7] yaml_2.2.0         rlang_0.3.0.1      R.oo_1.22.0       
[10] pillar_1.3.0       glue_1.3.0         withr_2.1.2       
[13] R.utils_2.7.0      RColorBrewer_1.1-2 modelr_0.1.2      
[16] readxl_1.1.0       bindr_0.1.1        plyr_1.8.4        
[19] munsell_0.5.0      gtable_0.2.0       workflowr_1.1.1   
[22] cellranger_1.1.0   rvest_0.3.2        R.methodsS3_1.7.1 
[25] evaluate_0.12      labeling_0.3       knitr_1.20        
[28] parallel_3.5.1     broom_0.5.0        Rcpp_0.12.19      
[31] scales_1.0.0       backports_1.1.2    jsonlite_1.5      
[34] hms_0.4.2          digest_0.6.18      stringi_1.2.4     
[37] grid_3.5.1         rprojroot_1.3-2    cli_1.0.1         
[40] tools_3.5.1        magrittr_1.5       lazyeval_0.2.1    
[43] crayon_1.3.4       whisker_0.3-2      pkgconfig_2.0.2   
[46] MASS_7.3-50        xml2_1.2.0         lubridate_1.7.4   
[49] reshape_0.8.8      assertthat_0.2.0   rmarkdown_1.10    
[52] httr_1.3.1         rstudioapi_0.8     R6_2.3.0          
[55] nlme_3.1-137       git2r_0.23.0       compiler_3.5.1    </code></pre>
</div>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<hr>
<p>
  This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a>
  analysis was created with
  <a href="https://github.com/jdblischak/workflowr">workflowr</a> 1.1.1
</p>
<hr>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
